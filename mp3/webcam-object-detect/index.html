<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Detection on Webcam</title>
    <!-- Tailwind CSS for modern styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- TensorFlow.js library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <!-- COCO-SSD model for object detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f0f4f8; /* A soft background color */
        }
        .container {
            max-width: 90%; /* Max width for the container */
            margin: 2rem auto; /* Center and add space */
            padding: 1.5rem;
            background-color: #ffffff;
            border-radius: 1rem; /* Rounded corners */
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1); /* Soft shadow */
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        video, canvas {
            display: block;
            border-radius: 0.75rem; /* Rounded corners for video/canvas */
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
            max-width: 100%; /* Ensure it fits the container */
            height: auto; /* Maintain aspect ratio */
        }
        .loading-message {
            color: #3b82f6; /* Blue color for loading message */
            font-weight: 600;
        }
        .error-message {
            color: #ef4444; /* Red color for error message */
            font-weight: 600;
        }
        .detection-info {
            margin-top: 1rem;
            width: 100%;
            text-align: center;
        }
        .detection-list {
            list-style: none;
            padding: 0;
            margin-top: 0.5rem;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 0.5rem;
        }
        .detection-item {
            background-color: #e0f2fe; /* Background color for detected items */
            color: #1e40af; /* Text color for detected items */
            padding: 0.3rem 0.8rem;
            border-radius: 0.5rem;
            font-size: 0.9rem;
            font-weight: 500;
        }
        .control-buttons {
            display: flex;
            gap: 1rem; /* Space between buttons */
            margin-top: 1rem;
            flex-wrap: wrap; /* Allow buttons to wrap on small screens */
            justify-content: center;
        }
        .action-button {
            background-color: #4CAF50; /* Green */
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.3s ease;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .action-button:hover {
            background-color: #45a049;
        }
        .action-button:active {
            background-color: #3e8e41;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            transform: translateY(1px);
        }
        #speechStatus {
            margin-top: 10px;
            font-style: italic;
            color: #6b7280;
        }
        .confidence-control {
            margin-top: 1rem;
            width: 80%;
            max-width: 400px;
            text-align: center;
        }
        .confidence-control label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 600;
            color: #4b5563;
        }
        .confidence-control input[type="range"] {
            width: 100%;
            -webkit-appearance: none;
            height: 8px;
            background: #d1d5db;
            border-radius: 5px;
            outline: none;
            opacity: 0.7;
            transition: opacity .2s;
        }
        .confidence-control input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            background: #3b82f6;
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .confidence-control input[type="range"]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            background: #3b82f6;
            border-radius: 50%;
            cursor: pointer;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        /* Custom styling for the voice selection dropdown */
        .voice-select {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 1rem;
            width: 80%;
            max-width: 400px;
            text-align: center;
        }
        .voice-select select {
            width: 100%;
            padding: 0.5rem;
            border-radius: 0.5rem;
            border: 1px solid #d1d5db;
            background-color: #f9fafb;
            font-size: 1rem;
        }
        .voice-select label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 600;
            color: #4b5563;
        }
    </style>
    <!-- The Google Translator widget has been commented out to avoid conflicts with the new translation functionality. -->
    <!--
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-VY5G7GWSPR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-VY5G7GWSPR');
    </script>
   
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2334449220276386" crossorigin="anonymous"></script>
    -->
</head>
<body class="bg-gray-100 flex items-center justify-center min-h-screen">
    <div class="container bg-white p-6 rounded-xl shadow-lg">
    <div style="text-align:center; width:100% !important">
        <style>
            /* Adjustments for Google Translator to be visible */
            .goog-te-banner-frame.skiptranslate,
            .skiptranslate > iframe {
                display: none !important;
            }
           
            body {
                top: 0px !important; 
            }

            .goog-te-menu-frame {
                max-width:100% !important; 
            }
            .goog-te-menu2 { 
                max-width: 100% !important;
                overflow-x: scroll !important;
                box-sizing:border-box !important; 
                height:auto !important; 
            }
           
            /* Hide unwanted elements without hiding the main widget */
            #goog-gt-tt, 
            #goog-gt-, 
            .goog-te-balloon-frame {
                display: none !important;
            } 
            .goog-text-highlight { 
                background: none !important; 
                box-shadow: none !important;
            }
           
            .goog-logo-link {
                display: none !important;
            }
            .goog-te-gadget {
                height: 28px !important; 
                overflow: hidden;
            }
        </style>
       
        <script type="text/javascript">
            function googleTranslateElementInit() {
                var lang_google='en';
               
                new google.translate.TranslateElement({pageLanguage: lang_google,
                                                             autoDisplay: true,
                                                             layout: google.translate.TranslateElement.InlineLayout.VERTICAL}, 
                                                             'google_translate_element');
               
                var el3 = document.querySelector('circle');
                var observer = new window.IntersectionObserver(([entry]) => {
                    document.getElementsByTagName("circle")[0].parentNode.parentNode.style.display = "none";
                }, {
                    root: null,
                    threshold: 0.1, // set offset 0.1 means trigger if atleast 10% of element in viewport
                });

                observer.observe(el3);
               
            }
        </script>

        <script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
       
        <strong>Translate</strong>
        <div id="google_translate_element"></div>
       
        <!--
        <br/>
        <br/>
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-format="fluid"
             data-ad-layout-key="-gc+4r+1p-d0+h0"
             data-ad-client="ca-pub-2334449220276386"
             data-ad-slot="6758976353"></ins>
        <script>
           (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
        -->
        <br/>
   
    </div>
       
        <h1 class="text-3xl font-bold text-gray-800 mb-4">Real-time Object Detection on Webcam</h1>
       
        <h3 class="text-1xl font-bold text-gray-800 mb-4">Developed with Gemini AI</h3>

        <div id="status" class="text-lg text-gray-600 mb-4 loading-message">Loading model... please wait.</div>
        <div id="error" class="text-lg text-red-600 mb-4 error-message hidden"></div>

        <div class="relative w-full max-w-xl">
            <video id="webcam" autoplay muted playsinline class="w-full rounded-lg"></video>
            <canvas id="outputCanvas" class="absolute top-0 left-0 w-full h-full rounded-lg"></canvas>
        </div>

        <!-- Updated control buttons section -->
        <div class="control-buttons">
            <button id="switchCameraButton" class="action-button">Switch Camera</button>
            <button id="askButton" class="action-button">Ask What I'm Seeing</button>
            <button id="toggleAutoSpeak" class="action-button">Enable Continuous Detection</button>
        </div>
        <div id="speechStatus" class="text-sm"></div>

        <div class="confidence-control">
            <label for="confidenceThreshold">Min Confidence (the less confidence: the more detection, but the less accurate): <span id="confidenceValue">50%</span></label>
            <input type="range" id="confidenceThreshold" min="0" max="100" value="50">
        </div>

        <!-- New dropdown for voice selection -->
        <div id="voiceControl" class="voice-select">
            <label for="voiceSelect">Select Voice:</label>
            <select id="voiceSelect" class="rounded-lg">
                <option>Voices...</option>
            </select>
        </div>

        <div id="detectionInfo" class="detection-info">
            <h2 class="text-xl font-semibold text-gray-700 mt-4 mb-2">Detected Objects:</h2>
            <ul id="detectionList" class="detection-list">
             </ul>
        </div>
       
        <!--
        <br/>
        <ins class="adsbygoogle"
             style="display:block"
             data-ad-client="ca-pub-2334449220276386"
             data-ad-slot="6625994850"
             data-ad-format="auto"
             data-full-width-responsive="true"></ins>
        <script>
             (adsbygoogle = window.adsbygoogle || []).push({});
        </script>
        <br/>
        -->
       
    </div>

    <script>
        // Get DOM element references
        const video = document.getElementById('webcam');
        const canvas = document.getElementById('outputCanvas');
        const ctx = canvas.getContext('2d');
        const statusDiv = document.getElementById('status');
        const errorDiv = document.getElementById('error');
        const detectionList = document.getElementById('detectionList');
        const switchCameraButton = document.getElementById('switchCameraButton');
        const askButton = document.getElementById('askButton');
        const toggleAutoSpeakButton = document.getElementById('toggleAutoSpeak');
        const speechStatusDiv = document.getElementById('speechStatus');
        const confidenceThresholdSlider = document.getElementById('confidenceThreshold');
        const confidenceValueSpan = document.getElementById('confidenceValue');
        const voiceSelect = document.getElementById('voiceSelect'); // New voice select element

        let model = undefined;
        let animationFrameId = null;
        let currentFacingMode = 'user';

        let lastDetectionTime = 0;
        const detectionInterval = 100; // ms

        let lastDetectedPredictions = [];
        let minConfidence = parseFloat(confidenceThresholdSlider.value) / 100;
       
        // --- Variables for continuous speech ---
        let isAutoSpeakEnabled = false;
        let lastSpokenObjects = new Set();
        const autoSpeakInterval = 5000; // 5 seconds
        let lastSpokenTime = 0;

        // --- Variables and Functions for Voice Selection (Web Speech API) ---
        let selectedVoice = null; // New variable to hold the selected voice object
        
        // --- Pre-translated phrases for various languages ---
        const translatedPhrases = {
            'en': {
                'i_see_a': 'I see a',
                'i_see_many': 'I see a ',
                'i_no_longer_see_a': 'I no longer see a',
                'no_objects_detected': 'No objects detected recently.',
            },
            'es': {
                'i_see_a': 'Veo un/una',
                'i_see_many': 'Veo un/una ',
                'i_no_longer_see_a': 'Ya no veo un/una',
                'no_objects_detected': 'No se detectaron objetos recientemente.',
            },
            'pt': {
                'i_see_a': 'Eu vejo um/uma',
                'i_see_many': 'Eu vejo um/uma ',
                'i_no_longer_see_a': 'Eu não vejo mais um/uma',
                'no_objects_detected': 'Nenhum objeto detectado recentemente.',
            },
            'ko': {
                'i_see_a': '하나의',
                'i_see_many': '하나의 ',
                'i_no_longer_see_a': '더 이상 하나의',
                'no_objects_detected': '최근에 감지된 개체가 없습니다.',
            },
            'vi': {
                'i_see_a': 'Tôi thấy một',
                'i_see_many': 'Tôi thấy một ',
                'i_no_longer_see_a': 'Tôi không còn thấy một',
                'no_objects_detected': 'Không có đối tượng nào được phát hiện gần đây.',
            },
            'ja': {
                'i_see_a': '私は一つ',
                'i_see_many': '私は一つ ',
                'i_no_longer_see_a': '私はもう一つ',
                'no_objects_detected': '最近検出されたオブジェクトはありません。',
            },
            'zh': {
                'i_see_a': '我看到一个',
                'i_see_many': '我看到一个',
                'i_no_longer_see_a': '我不再看到一个',
                'no_objects_detected': '最近没有检测到物体。',
            },
            'fr': {
                'i_see_a': 'Je vois un',
                'i_see_many': 'Je vois un ',
                'i_no_longer_see_a': 'Je ne vois plus un',
                'no_objects_detected': "Aucun objet n'a été détecté récemment.",
            },
            'de': {
                'i_see_a': 'Ich sehe ein',
                'i_see_many': 'Ich sehe ein ',
                'i_no_longer_see_a': 'Ich sehe kein',
                'no_objects_detected': 'Kürzlich wurden keine Objekte erkannt.',
            },
            'it': {
                'i_see_a': 'Vedo un/una',
                'i_see_many': 'Vedo un/una ',
                'i_no_longer_see_a': 'Non vedo più un/una',
                'no_objects_detected': 'Nessun oggetto rilevato di recente.',
            },
            'ru': {
                'i_see_a': 'Я вижу',
                'i_see_many': 'Я вижу ',
                'i_no_longer_see_a': 'Я больше не вижу',
                'no_objects_detected': 'Недавно не было обнаружено ни одного объекта.',
            },
            'af': {
                'i_see_a': 'Ek sien \'n',
                'i_see_many': 'Ek sien \'n ',
                'i_no_longer_see_a': 'Ek sien nie meer \'n',
                'no_objects_detected': 'Geen voorwerpe onlangs opgespoor nie.',
            }
        };

        const andPhrase = {
            en: ' and ',
            es: ' y ',
            pt: ' e ',
            ko: '과(와)',
            vi: ' và ',
            ja: 'と',
            zh: '和',
            fr: ' et ',
            de: ' und ',
            it: ' e ',
            ru: ' и ',
            af: ' en '
        };

        /**
         * A helper function to get the correct translated phrase.
         * Falls back to English if the language is not found.
         * @param {string} key The key for the phrase (e.g., 'i_see_a').
         * @param {string} langCode The language code (e.g., 'es').
         * @returns {string} The translated phrase.
         */
        function getTranslation(key, langCode) {
            const shortLangCode = langCode.split(/[-_]/)[0];
            return (translatedPhrases[shortLangCode] && translatedPhrases[shortLangCode][key]) ?
                   translatedPhrases[shortLangCode][key] :
                   translatedPhrases['en'][key];
        }
        
        /**
         * Populates the voice selection dropdown with the specified languages.
         * Sorts the list alphabetically and sets an English voice as the default.
         */
        function populateVoiceList() {
            if (!('speechSynthesis' in window)) {
                console.warn("Web Speech API not supported.");
                voiceSelect.innerHTML = '<option>Speech not supported</option>';
                voiceSelect.disabled = true;
                return;
            }

            const allVoices = window.speechSynthesis.getVoices();
            console.log("All available voices:", allVoices); // Log all voices for debugging
            
            const supportedShortLangs = [
                'en', 'es', 'pt', 'ko', 'vi', 'ja', 'zh', 'fr', 'de', 'it', 'ru', 'af'
            ];

            // Filter voices by checking if their language code starts with any of the supported short codes
            const filteredVoices = allVoices.filter(voice => {
                const shortLang = voice.lang.split(/[-_]/)[0];
                return supportedShortLangs.includes(shortLang);
            });
            
            // Sort the voices alphabetically by language
            filteredVoices.sort((a, b) => a.lang.localeCompare(b.lang));

            voiceSelect.innerHTML = '';

            if (filteredVoices.length === 0) {
                console.warn("No suitable voices found.");
                voiceSelect.innerHTML = '<option>No suitable voices available</option>';
                voiceSelect.disabled = true;
                return;
            }
            
            voiceSelect.disabled = false;
            
            let defaultVoice = null;
            filteredVoices.forEach(voice => {
                const option = document.createElement('option');
                option.textContent = `${voice.name} (${voice.lang})`;
                option.setAttribute('data-name', voice.name);
                option.setAttribute('data-lang', voice.lang);
                voiceSelect.appendChild(option);

                if (voice.lang.startsWith('en') && !defaultVoice) {
                    defaultVoice = voice;
                }
            });

            if (defaultVoice) {
                selectedVoice = defaultVoice;
                voiceSelect.value = `${defaultVoice.name} (${defaultVoice.lang})`;
            } else {
                selectedVoice = filteredVoices[0];
                voiceSelect.value = `${filteredVoices[0].name} (${filteredVoices[0].lang})`;
            }
            
            console.log("Filtered voices loaded. Default voice selected:", selectedVoice ? selectedVoice.name : 'None');
        }

        if ('speechSynthesis' in window) {
            window.speechSynthesis.onvoiceschanged = populateVoiceList;
            populateVoiceList();
        }

        /**
         * Speaks the given text using the currently selected voice and language.
         * @param {string} textToSpeak The text to be spoken.
         */
        async function speakDetectedObjects(textToSpeak) {
            if ('speechSynthesis' in window && selectedVoice) {
                if (window.speechSynthesis.speaking) {
                    window.speechSynthesis.cancel();
                }

                speechStatusDiv.textContent = "Speaking...";
                const utterance = new SpeechSynthesisUtterance(textToSpeak);
                utterance.voice = selectedVoice;
                utterance.lang = selectedVoice.lang;
                utterance.pitch = 1;
                utterance.rate = 1;

                utterance.onend = () => {
                    speechStatusDiv.textContent = `Last announcement: "${textToSpeak}"`;
                };
                utterance.onerror = (event) => {
                    console.error("Speech synthesis error:", event.error);
                    speechStatusDiv.textContent = "Error speaking.";
                };

                window.speechSynthesis.speak(utterance);
            } else {
                speechStatusDiv.textContent = `Last announcement: "${textToSpeak}"`;
                console.warn("Web Speech API not supported or no voice selected.");
            }
        }

        /**
         * Event handler for when the user selects a new voice from the dropdown.
         */
        voiceSelect.addEventListener('change', () => {
            const selectedOption = voiceSelect.options[voiceSelect.selectedIndex];
            const voices = window.speechSynthesis.getVoices();
            selectedVoice = voices.find(voice => voice.name === selectedOption.getAttribute('data-name') && voice.lang === selectedOption.getAttribute('data-lang'));
            console.log("New voice selected:", selectedVoice ? selectedVoice.name : 'None');
        });

        function displayError(message) {
            errorDiv.textContent = `Error: ${message}`;
            errorDiv.classList.remove('hidden');
            statusDiv.classList.add('hidden');
        }

        async function setupWebcam(facingMode) {
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }

            try {
                statusDiv.textContent = `Starting camera (${facingMode === 'user' ? 'front' : 'rear'})...`;
                errorDiv.classList.add('hidden');
               
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: facingMode }
                });
               
                video.srcObject = stream;
                currentFacingMode = facingMode;

                await new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        resolve(video);
                    };
                });

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
               
                statusDiv.textContent = 'Webcam started. Loading model...';
                return video;
            } catch (err) {
                console.error(`Error accessing webcam (${facingMode}):`, err);
                if (facingMode === 'user' && err.name === 'OverconstrainedError') {
                    displayError('Front camera not available, trying rear camera...');
                    return setupWebcam('environment');
                } else if (facingMode === 'environment' && err.name === 'OverconstrainedError') {
                    displayError('Rear camera not available, trying front camera...');
                    return setupWebcam('user');
                } else {
                    displayError(`Could not access webcam. Make sure you have granted permissions. (${err.message})`);
                    return null;
                }
            }
        }

        async function loadModel() {
            try {
                statusDiv.textContent = 'Loading model...';
                model = await cocoSsd.load();
                statusDiv.textContent = 'Model loaded. Starting detection...';
                statusDiv.classList.add('hidden');
            } catch (err) {
                console.error('Error loading model:', err);
                displayError('Could not load the object detection model.');
            }
        }

        async function detectObjects(currentTime) {
            if (!model || video.readyState !== 4) {
                animationFrameId = requestAnimationFrame(detectObjects);
                return;
            }

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            if (currentTime - lastDetectionTime > detectionInterval) {
                lastDetectionTime = currentTime;

                const predictions = await model.detect(video);
               
                lastDetectedPredictions = predictions.filter(prediction => prediction.score >= minConfidence);

                detectionList.innerHTML = '';
                const currentDetectedClasses = new Set();
               
                lastDetectedPredictions.forEach(prediction => {
                    const [x, y, width, height] = prediction.bbox;
                    const label = prediction.class;
                    const score = Math.round(prediction.score * 100);

                    ctx.beginPath();
                    ctx.rect(x, y, width, height);
                    ctx.lineWidth = 2;
                    ctx.strokeStyle = '#00FF00';
                    ctx.fillStyle = '#00FF00';
                    ctx.stroke();

                    const fontSize = 16;
                    ctx.font = `${fontSize}px Arial`;
                    const text = `${label} (${score}%)`;
                    const textWidth = ctx.measureText(text).width;
                    ctx.fillRect(x, y > fontSize ? y - fontSize : y, textWidth + 8, fontSize + 4);

                    ctx.fillStyle = '#000000';
                    ctx.fillText(text, x + 4, y > fontSize ? y - 4 : y + fontSize + 4);

                    const listItem = document.createElement('li');
                    listItem.className = 'detection-item';
                    listItem.textContent = `${label} (${score}%)`;
                    detectionList.appendChild(listItem);
               
                    currentDetectedClasses.add(label);
                });
               
                // --- Logic for continuous speech ---
                if (isAutoSpeakEnabled && currentTime - lastSpokenTime > autoSpeakInterval) {
                    const newObjects = Array.from(currentDetectedClasses).filter(
                        object => !lastSpokenObjects.has(object)
                    );

                    const lostObjects = Array.from(lastSpokenObjects).filter(
                        object => !currentDetectedClasses.has(object)
                    );

                    let speechText = '';
                    const langCode = selectedVoice ? selectedVoice.lang.split(/[-_]/)[0] : 'en';

                    if (newObjects.length > 0) {
                        const last = newObjects.length > 1 ? `${andPhrase[langCode] || ' and '}a ${newObjects.pop()}` : '';
                        const comma = newObjects.length > 0 && last ? ', ' : '';
                        speechText += `${getTranslation('i_see_a', langCode)} ${newObjects.join(comma + 'a ')}${last}.`;
                    }

                    if (lostObjects.length > 0) {
                        if (speechText !== '') speechText += ' ';
                        speechText += `${getTranslation('i_no_longer_see_a', langCode)} ${lostObjects.join(', ')}.`;
                    }

                    if (speechText !== '') {
                        speakDetectedObjects(speechText);
                        lastSpokenTime = currentTime;
                    }
               
                    lastSpokenObjects = currentDetectedClasses;
                }
            }

            animationFrameId = requestAnimationFrame(detectObjects);
        }

        async function askWhatIsBeingSeen() {
            if (lastDetectedPredictions.length > 0) {
                const detectedClasses = Array.from(new Set(lastDetectedPredictions.map(p => p.class)));
                const langCode = selectedVoice ? selectedVoice.lang.split(/[-_]/)[0] : 'en';

                let speechText;
                const andPhraseText = andPhrase[langCode] || ' and ';
                
                let listString;
                if (detectedClasses.length === 1) {
                    listString = detectedClasses[0];
                    speechText = `${getTranslation('i_see_a', langCode)} ${listString}.`;
                } else {
                    const last = detectedClasses.pop();
                    listString = `${detectedClasses.join(', ')}${andPhraseText}${last}`;
                    speechText = `${getTranslation('i_see_many', langCode)} ${listString}.`;
                }
                
                await speakDetectedObjects(speechText);
            } else {
                const langCode = selectedVoice ? selectedVoice.lang.split(/[-_]/)[0] : 'en';
                speechStatusDiv.textContent = getTranslation('no_objects_detected', langCode);
            }
        }

        async function switchCamera() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }

            const newFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
            const webcamReady = await setupWebcam(newFacingMode);

            if (webcamReady) {
                if (model) {
                    lastDetectionTime = 0;
                    lastDetectedPredictions = [];
                    lastSpokenObjects = new Set();
                    animationFrameId = requestAnimationFrame(detectObjects);
                } else {
                    await loadModel();
                    if (model) {
                        lastDetectionTime = 0;
                        lastDetectedPredictions = [];
                        lastSpokenObjects = new Set();
                        animationFrameId = requestAnimationFrame(detectObjects);
                    }
                }
            }
        }
       
        function toggleAutoSpeak() {
            isAutoSpeakEnabled = !isAutoSpeakEnabled;
            toggleAutoSpeakButton.textContent = isAutoSpeakEnabled ? 'Disable Continuous Detection' : 'Enable Continuous Detection';
            if (isAutoSpeakEnabled) {
                speechStatusDiv.textContent = 'Continuous detection enabled.';
                lastSpokenTime = 0;
            } else {
                speechStatusDiv.textContent = '';
                window.speechSynthesis.cancel();
            }
        }
        
        /*
        // Add event listeners to buttons
        switchCameraButton.addEventListener('click', switchCamera);
        askButton.addEventListener('click', askWhatIsBeingSeen);
        toggleAutoSpeakButton.addEventListener('click', toggleAutoSpeak);

        // Event listener for the confidence slider
        confidenceThresholdSlider.addEventListener('input', (event) => {
            minConfidence = parseFloat(event.target.value) / 100;
            confidenceValueSpan.textContent = `${event.target.value}%`;
        });

        // Startup function when the window has fully loaded
        window.onload = async function() {
            const webcamReady = await setupWebcam('user');
            if (webcamReady) {
               
                await loadModel();
               
                if (model) {
                    animationFrameId = requestAnimationFrame(detectObjects);
                }
            }
        };*/
        
        async function load_function()
        {
            // Add event listeners to buttons
            switchCameraButton.addEventListener('click', switchCamera);
            askButton.addEventListener('click', askWhatIsBeingSeen);
            toggleAutoSpeakButton.addEventListener('click', toggleAutoSpeak);

            // Event listener for the confidence slider
            confidenceThresholdSlider.addEventListener('input', (event) => {
                minConfidence = parseFloat(event.target.value) / 100;
                confidenceValueSpan.textContent = `${event.target.value}%`;
            });
            
            const webcamReady = await setupWebcam('user');
            if (webcamReady) {
               
                await loadModel();
               
                if (model) {
                    animationFrameId = requestAnimationFrame(detectObjects);
                }
            }
        }
        
        document.addEventListener('DOMContentLoaded', load_function);

        window.onbeforeunload = () => {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            if ('speechSynthesis' in window)
            {
                window.speechSynthesis.cancel();
            }
        };
       
    </script>
</body>
</html>
